{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6fe04d9",
   "metadata": {},
   "source": [
    "# MEG Data Preprocessing Pipeline - Subject 95\n",
    "\n",
    "## Overview\n",
    "This notebook implements a standardized preprocessing pipeline for OPM-MEG data analysis. The pipeline is designed for **subject sub-95** (healthy participant)\n",
    "and processes one session at a time through a modular, reusable framework.\n",
    "\n",
    "## Research Context\n",
    "- **Subject**: sub-95 (healthy control participant)\n",
    "- **Data Type**: OPM-MEG recordings (.fif format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162b5877",
   "metadata": {},
   "source": [
    "## 0 - Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- LIBRARIES ----\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "from mne.preprocessing import compute_proj_hfc\n",
    "\n",
    "sys.path.append('../source')\n",
    "\n",
    "\n",
    "# from find_paths import get_onedrive_path\n",
    "# from plot_functions import (plot_raw_vs_processed,\n",
    "#                             plot_channels_comparison,)\n",
    "\n",
    "try:\n",
    "    import utils.load_utils as load_utils\n",
    "    # change working directory to lid_opm if utils not found\n",
    "except:\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "    import utils.load_utils as load_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4fb2a0",
   "metadata": {},
   "source": [
    "## 1. Define settings and load data (incl epoched events)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f62cd",
   "metadata": {},
   "source": [
    "### Load configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_ID = 'sub-95'\n",
    "SES_ID = 'Dec'\n",
    "\n",
    "\n",
    "# ---- 1.2 LOAD CONFIGURATION  ----\n",
    "config = load_utils.load_subject_config(SUB_ID)\n",
    "\n",
    "# Show available tasks from the config file\n",
    "available_tasks = config['tasks'][f\"ses-{SES_ID}\"]\n",
    "print(\"=\"*60)\n",
    "print(\"Available tasks in the configuration file:\")\n",
    "print(\"=\"*60)\n",
    "for task in available_tasks:\n",
    "    print(f\"- {task}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e74e65c",
   "metadata": {},
   "source": [
    "### Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Define the task for this run (select one from the list above)\n",
    "TASK = 'testArdgonogo3'  #'behavfederico1' \n",
    "\n",
    "# find filepath\n",
    "ses_path = os.path.join(\n",
    "    load_utils.get_onedrive_path('source_data'),\n",
    "    SUBJECT_ID,\n",
    "    'OPM_MEG',\n",
    "    f'ses-{SES_ID}'\n",
    ")\n",
    "files = os.listdir(ses_path)\n",
    "sel_fname = [f for f in files if TASK in f and f.endswith('.fif')][0]\n",
    "\n",
    "file_path = os.path.join(ses_path, sel_fname)\n",
    "assert os.path.exists(file_path), 'WARNING. FILEPATH NOTE EXISTING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6dd9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AND EXPLORE DATA ----\n",
    "\n",
    "\n",
    "raw = mne.io.read_raw_fif(file_path, preload=True, verbose= True)\n",
    "print(\"File loaded successfully.\")\n",
    "\n",
    "# Display the data header (raw.info)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA HEADER:\")\n",
    "print(\"=\"*60)\n",
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the raw.info, extract and display the sampling frequency (sfreq):\n",
    "\n",
    "SFREQ = raw.info['sfreq']\n",
    "print(\"=\"*60)\n",
    "print(f\"Sampling Frequency (sfreq): {SFREQ} Hz\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d642c",
   "metadata": {},
   "source": [
    "### 1.5 Verify Sensor Geometry\n",
    "\n",
    "The plot displays:\n",
    "-   **Sensor Positions**: Each sensor's location in 3D space, shown as a black dot.\n",
    "-   **Orientation Vectors**: The local coordinate system of each sensor, represented by three colored arrows:\n",
    "    -   **Red**: The sensor's local X-axis.\n",
    "    -   **Green**: The sensor's local Y-axis.\n",
    "    -   **Blue**: The sensor's local Z-axis (normal vector, pointing away from the head)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906fcb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED 3D SENSOR GEOMETRY VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"Plotting sensor positions and orientation vectors from raw.info.\")\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Get channel names from the raw object\n",
    "chnames = raw.ch_names\n",
    "\n",
    "for ch_name in chnames:\n",
    "    # Find the channel's dictionary in the info structure\n",
    "    ch_info = raw.info['chs'][raw.ch_names.index(ch_name)]\n",
    "    \n",
    "    # Extract position and all THREE orientation vectors from the 'loc' array\n",
    "    pos = ch_info['loc'][:3]    # Position (x, y, z)\n",
    "    ori_x = ch_info['loc'][3:6]  # First orientation vector (X-axis)\n",
    "    ori_y = ch_info['loc'][6:9]  # Second orientation vector (Y-axis)\n",
    "    ori_z = ch_info['loc'][9:12] # Third orientation vector (Z-axis, normal)\n",
    "    \n",
    "    # Plot sensor location\n",
    "    ax.scatter(*pos, c='black', s=20)\n",
    "\n",
    "    # Plot orientation vectors (scaled for visibility)\n",
    "    scale = 0.01\n",
    "    ax.quiver(*pos, *ori_x, length=scale, color='red', label='Ori-X' if ch_name == chnames[0] else \"\")\n",
    "    ax.quiver(*pos, *ori_y, length=scale, color='green', label='Ori-Y' if ch_name == chnames[0] else \"\")\n",
    "    ax.quiver(*pos, *ori_z, length=scale, color='blue', label='Ori-Z' if ch_name == chnames[0] else \"\")\n",
    "\n",
    "ax.set_xlabel('X (m)')\n",
    "ax.set_ylabel('Y (m)')\n",
    "ax.set_zlabel('Z (m)')\n",
    "ax.set_title(\"Sensor Positions and Orientation Vectors\")\n",
    "ax.legend()\n",
    "\n",
    "# Set aspect ratio to be equal\n",
    "ax.set_box_aspect([np.ptp(ax.get_xlim()), np.ptp(ax.get_ylim()), np.ptp(ax.get_zlim())])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113107f",
   "metadata": {},
   "source": [
    "### 1.6 Define channel lists from config file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c32e362",
   "metadata": {},
   "source": [
    "### Note on Available MEG Components\n",
    "\n",
    "For this specific dataset, the raw `.fif` files contain only the **Y and Z magnetic field components** from the OPM sensors. This is the expected format for this recording, and the subsequent analysis will proceed using these two available components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e09759",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec96a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1.6 DEFINE CHANNEL LISTS FROM CONFIG ----\n",
    "\n",
    "# Dynamically identify MEG channels from the raw data based on naming convention\n",
    "meg_channels = {'y': [ch_name for ch_name in raw.ch_names\n",
    "                      if '_by' in ch_name],\n",
    "                'z': [ch_name for ch_name in raw.ch_names\n",
    "                      if '_bz' in ch_name]}\n",
    "\n",
    "all_meg_channels = meg_channels['y'] + meg_channels['z']\n",
    "\n",
    "# Verify that channels were found\n",
    "if not all_meg_channels:\n",
    "    raise RuntimeError(\"No MEG channels with '_by' or '_bz' found in the data. Please check channel names.\")\n",
    "\n",
    "# Select the MEG data from the raw file\n",
    "meg_data = raw.copy().pick(all_meg_channels)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MEG CHANNEL SELECTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Selected {len(meg_data.ch_names)} MEG channels out of {len(raw.ch_names)} total channels.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a01e56a",
   "metadata": {},
   "source": [
    "## 2. Preprocessing: Resampling and Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03db09c",
   "metadata": {},
   "source": [
    "### 2.1 Load preprocessing settings and resample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 2.1 LOAD PREPROCESSING SETTINGS AND RESAMPLE ----\n",
    "\n",
    "# Load the general preprocessing settings\n",
    "preproc_settings = load_utils.load_preproc_config()\n",
    "\n",
    "TARGET_SFREQ = preproc_settings['TARGET_SFREQ']\n",
    "\n",
    "\n",
    "# Resample the data if the original sampling frequency is higher than the target\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESAMPLING DATA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original sampling rate: {meg_data.info['sfreq']} Hz.\")\n",
    "meg_data.resample(TARGET_SFREQ, npad='auto')\n",
    "print(f\"New sampling rate: {meg_data.info['sfreq']} Hz\")\n",
    "\n",
    "# Convert MEG data from Tesla (T) to picoTesla (pT)\n",
    "print(\"Converting MEG units from T to pT...\")\n",
    "meg_data.apply_function(lambda x: x * 1e12)\n",
    "\n",
    "#To visualize the effects of our preprocessing, I create a copy of the selected MEG data \n",
    "# before any filtering or resampling.\n",
    "meg_data_unprocessed = meg_data.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e1fdbc",
   "metadata": {},
   "source": [
    "### 2.2 Apply bandpass and notch filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414d5b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 2.2 APPLY BANDPASS AND NOTCH FILTERS ----\n",
    "\n",
    "# Extract filter parameters from the settings file\n",
    "BANDPASS_LOW = preproc_settings['BANDPASS_LOW']\n",
    "BANDPASS_HIGH = preproc_settings['BANDPASS_HIGH']\n",
    "NOTCH_FREQS = preproc_settings['NOTCH_FREQS']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"APPLYING FILTERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Apply bandpass filter\n",
    "print(f\"Applying bandpass filter between {BANDPASS_LOW} Hz and {BANDPASS_HIGH} Hz...\")\n",
    "meg_data.filter(\n",
    "    l_freq=BANDPASS_LOW,\n",
    "    h_freq=BANDPASS_HIGH,\n",
    "    method='fir',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Apply notch filter to remove power line noise\n",
    "print(f\"Applying notch filter at {NOTCH_FREQS} Hz...\")\n",
    "meg_data.notch_filter(\n",
    "    freqs=NOTCH_FREQS,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Filtering and scaling complete.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6457047",
   "metadata": {},
   "source": [
    "### 2.3 Homogeneous Field Correction (HFC)\n",
    "\n",
    "Next, we apply Homogeneous Field Correction (HFC) to suppress external magnetic field interference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2513383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 2.3 APPLY HOMOGENEOUS FIELD CORRECTION (HFC) ----\n",
    "\n",
    "# Get HFC order from preprocessing settings\n",
    "HFC_ORDER = preproc_settings['HFC_ORDER']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"APPLYING HOMOGENEOUS FIELD CORRECTION (HFC)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Computing HFC projectors with order={HFC_ORDER}...\")\n",
    "\n",
    "# Compute and apply HFC projectors\n",
    "proj_hfc = compute_proj_hfc(meg_data.info, order=HFC_ORDER)\n",
    "meg_data.add_proj(proj_hfc)\n",
    "meg_data.apply_proj()\n",
    "\n",
    "print(\"HFC projectors have been applied to the data.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d8bd1",
   "metadata": {},
   "source": [
    "### 2.4 Visual Comparison: Raw vs. Processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c6e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- PLOT COMPONENTS COMPARISON ----\n",
    "\n",
    "# Define time window\n",
    "START_TIME = 0  # \n",
    "DURATION = 300  # in seconds\n",
    "STOP_TIME = START_TIME + DURATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c677260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- PLOT Y-COMPONENT COMPARISON ----\n",
    "PLOT_AX = 'z'\n",
    "\n",
    "# Extract data and time for the plot for Y-components\n",
    "# Unprocessed data\n",
    "start_idx_unprocessed = meg_data_unprocessed.time_as_index(START_TIME)[0]\n",
    "stop_idx_unprocessed = meg_data_unprocessed.time_as_index(STOP_TIME)[0]\n",
    "y_data_unprocessed = meg_data_unprocessed.get_data(\n",
    "    picks=meg_channels[PLOT_AX],\n",
    "    start=start_idx_unprocessed,\n",
    "    stop=stop_idx_unprocessed,\n",
    ")\n",
    "time_unprocessed = meg_data_unprocessed.times[\n",
    "    start_idx_unprocessed:stop_idx_unprocessed\n",
    "]\n",
    "\n",
    "# Processed data\n",
    "start_idx_processed = meg_data.time_as_index(START_TIME)[0]\n",
    "stop_idx_processed = meg_data.time_as_index(STOP_TIME)[0]\n",
    "y_data_processed = meg_data.get_data(\n",
    "    picks=meg_channels[PLOT_AX], start=start_idx_processed, stop=stop_idx_processed\n",
    ")\n",
    "time_processed = meg_data.times[start_idx_processed:stop_idx_processed]\n",
    "\n",
    "# Generate colors for the channels\n",
    "colors_y = plt.cm.rainbow(np.linspace(0, 1, len(meg_channels[PLOT_AX])))\n",
    "\n",
    "plot_channels_comparison(\n",
    "    time_0=time_unprocessed,\n",
    "    time_1=time_processed,\n",
    "    raw_channels=y_data_unprocessed,\n",
    "    filtered_channels=y_data_processed,\n",
    "    raw_labels=meg_channels[PLOT_AX],\n",
    "    filtered_labels=meg_channels[PLOT_AX],\n",
    "    colors=colors_y,\n",
    "    rec_label=f\"{SUB_ID} - {TASK}\",\n",
    "    y_label=\"Amplitude (pT)\",\n",
    "    axis_label=PLOT_AX,\n",
    "    sync_ylim=False,\n",
    "    show_legend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e57150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96490f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3789a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_topoBands_fromRaw(\n",
    "    rawObj,\n",
    "    bands_to_plot={'low-freq': [4, 12],\n",
    "                   'beta': [15, 30],\n",
    "                   'gamma': [65, 85]},\n",
    "):\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "\n",
    "    for i, (band, fband) in enumerate(bands_to_plot.items()):\n",
    "\n",
    "        # Band-pass filter raw data\n",
    "        raw_band = rawObj.copy().filter(\n",
    "            fband[0], fband[1],\n",
    "            fir_design=\"firwin\",\n",
    "        )\n",
    "\n",
    "        # Compute PSD (Power Spectral Density)\n",
    "        psds, freqs = mne.time_frequency.psd_array_welch(\n",
    "            raw_band.get_data(),\n",
    "            sfreq=int(rawObj.info['sfreq']),\n",
    "            fmin=fband[0], \n",
    "            fmax=fband[1],\n",
    "            n_fft=int(rawObj.info['sfreq'])\n",
    "        )\n",
    "\n",
    "        # Average across frequencies in the band\n",
    "        psd_mean = psds.mean(axis=-1)  # shape (n_channels,)\n",
    "\n",
    "        # Pick channel info (EEG/MEG sensors only)\n",
    "        picks = mne.pick_types(rawObj.info, meg=True, eeg=False)\n",
    "\n",
    "        # Plot topomap\n",
    "        topofig, topoax = mne.viz.plot_topomap(\n",
    "            psd_mean[picks],\n",
    "            rawObj.info,\n",
    "            cmap=\"viridis\",\n",
    "            show=False,\n",
    "            axes=axes[i],\n",
    "        )\n",
    "        axes[i].set_title(f'{band} activity ({fband[0]}-{fband[1]} Hz)',\n",
    "                        size=16,)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # plt.savefig(figpath, dpi=300, facecolor='w',)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7134ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for AX in ['z', 'y']:\n",
    "\n",
    "    TEMP_DAT = raw.copy().pick(meg_channels[AX])\n",
    "\n",
    "    print(f'TOPOGRAM for {AX}:')\n",
    "    plot_topoBands_fromRaw(rawObj=TEMP_DAT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b26b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527ce796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87dbc20f",
   "metadata": {},
   "source": [
    "## 3. Create Epochs from Events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da96558",
   "metadata": {},
   "source": [
    "For the `withemgacc` task, the event trigger signals were not recorded on a standard trigger channel within the `.fif` file. Instead, they were saved to a separate `.trg` file, which is only available for this specific recording session.\n",
    "\n",
    "To ensure a self-contained and reproducible analysis, the timestamps from this `.trg` file have been manually extracted and stored within the `config_sub95.json` file under the `event_timestamps` key. The following cells load these pre-defined timestamps from the configuration to create the event markers for epoching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1466c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 3.1 LOAD EVENT TIMESTAMPS FROM CONFIG ----\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"LOADING EVENT TIMESTAMPS FOR TASK: '{TASK}'\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Get event timestamps from the loaded configuration file for the current task\n",
    "    event_times = np.array(config['event_timestamps'][TASK])\n",
    "    \n",
    "    if event_times.size == 0:\n",
    "        raise ValueError(f\"No event timestamps found for task '{TASK}' in the config file.\")\n",
    "    \n",
    "    print(f\"Successfully loaded {len(event_times)} event timestamps from config.\")\n",
    "    print(\"Event times (in seconds):\")\n",
    "    print(event_times)\n",
    "\n",
    "except KeyError:\n",
    "    print(f\"Error: 'event_timestamps' or task '{TASK}' not found in the config file.\")\n",
    "    event_times = np.array([]) # Ensure event_times exists but is empty\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    event_times = np.array([])\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e055455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 3.2 CREATE MNE-COMPATIBLE EVENTS ARRAY ----\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING MNE EVENTS ARRAY FROM TIMESTAMPS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if event_times.size > 0:\n",
    "    # MNE requires event markers as sample indices, not seconds.\n",
    "    # Convert the timestamps in seconds to sample indices by multiplying by the sampling frequency.\n",
    "    # Use the sampling frequency from the unprocessed data to ensure perfect alignment.\n",
    "    sfreq_unprocessed = meg_data_unprocessed.info['sfreq']\n",
    "    event_samples = (event_times * sfreq_unprocessed).astype(int)\n",
    "    print(f\"Converted {len(event_times)} event timestamps (in seconds) to sample indices using sfreq={sfreq_unprocessed} Hz.\")\n",
    "\n",
    "    # The MNE events array has 3 columns: [sample_index, previous_event_id, event_id].\n",
    "    # We use a single event_id (1) for all our triggers.\n",
    "    events_array = np.array([event_samples, np.zeros_like(event_samples), np.ones_like(event_samples)]).T\n",
    "\n",
    "    print(f\"\\nCreated events array with shape: {events_array.shape}\")\n",
    "    print(\"This array contains ALL events.\")\n",
    "    print(\"Showing the full array for verification:\")\n",
    "    print(events_array)\n",
    "else:\n",
    "    print(\"Skipping MNE event array creation because no event times were loaded.\")\n",
    "    events_array = np.array([])\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 3.3 CREATE EPOCHS FROM EVENTS ----\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING EPOCHS FROM EVENTS ARRAY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if events_array.size > 0:\n",
    "    # Define epoching parameters from the preprocessing settings\n",
    "    TMIN = preproc_settings.get('EPOCH_TMIN', -1.0)  # Start time before event\n",
    "    TMAX = preproc_settings.get('EPOCH_TMAX', 3.0)   # End time after event\n",
    "    BASELINE = tuple(preproc_settings.get('EPOCH_BASELINE', [-1.0, 0])) # Baseline period\n",
    "\n",
    "    # Create epochs from the preprocessed data using the full events_array\n",
    "    epochs = mne.Epochs(\n",
    "        meg_data,\n",
    "        events=events_array,\n",
    "        tmin=TMIN,\n",
    "        tmax=TMAX,\n",
    "        baseline=BASELINE,\n",
    "        preload=True,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    print(f\"Successfully created {len(epochs)} epochs.\")\n",
    "    print(f\"Each epoch runs from {TMIN}s to {TMAX}s relative to the event.\")\n",
    "    print(f\"Baseline correction was applied using the interval {BASELINE}s.\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Inspect the epochs object\n",
    "    print(\"\\nEpochs object info:\")\n",
    "    print(epochs)\n",
    "\n",
    "else:\n",
    "    print(\"Skipping epoch creation because no events were found.\")\n",
    "    epochs = None\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16b919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lid_opm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
